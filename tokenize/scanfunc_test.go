package tokenize_test

import (
	"github.com/Jumpaku/sqanner/tokenize"
	"testing"
)

type testcaseScan struct {
	message   string
	input     string
	wantLen   int
	wantKind  tokenize.TokenKind
	shouldErr bool
}
type scanFunc func(*tokenize.ScanState) (int, tokenize.TokenKind, error)

func checkScan(t *testing.T, testcase testcaseScan, sut scanFunc) {
	t.Helper()

	gotLen, gotKind, gotErr := sut(&tokenize.ScanState{Input: []rune(testcase.input)})
	if (gotErr != nil) != testcase.shouldErr {
		if testcase.shouldErr {
			t.Errorf(`%s: input=%q:
	err is expected but got nil`, testcase.message, testcase.input)
		} else {
			t.Errorf(`%s: input=%q:
	err is not expected but got %v`, testcase.message, testcase.input, gotErr)
		}

	}

	if !(gotLen == testcase.wantLen && gotKind == testcase.wantKind) {
		t.Errorf(`%s: input=%q:
	got  : len=%5d kind=%v:
	want : len=%5d kind=%v`, testcase.message, testcase.input, gotLen, gotKind, testcase.wantLen, testcase.wantKind)
	}
}

func TestSpaces(t *testing.T) {
	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `starts with non white space`,
			input:     `a`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `spaces ends with EOF`,
			input:     " \t\n\v\f\r",
			wantLen:   6,
			wantKind:  tokenize.TokenSpace,
			shouldErr: false,
		},
		{message: `spaces ends with alphabet`,
			input:     " \t\n\v\f\r A",
			wantLen:   7,
			wantKind:  tokenize.TokenSpace,
			shouldErr: false,
		},
	}

	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.Spaces)
	}
}

func TestComment(t *testing.T) {
	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `non comment`,
			input:     `a`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `empty comment starts with # ends with EOF`,
			input:     "#",
			wantLen:   1,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `empty comment starts with # ends with \n`,
			input:     "#\n",
			wantLen:   2,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `empty comment starts with // ends with EOF`,
			input:     "//",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `empty comment starts with // ends with \n`,
			input:     "//\n",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `empty comment starts with -- ends with EOF`,
			input:     "--",
			wantLen:   2,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `empty comment starts with -- ends with \n`,
			input:     "--\n",
			wantLen:   3,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `empty comment starts with /* ends with */`,
			input:     "/**/",
			wantLen:   4,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `comment starts with # ends with EOF`,
			input:     "#abc",
			wantLen:   4,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `comment starts with # ends with \n`,
			input:     "#abc\n",
			wantLen:   5,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `comment starts with // ends with EOF`,
			input:     "//abc",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `comment starts with // ends with \n`,
			input:     "//abc\n",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `comment starts with -- ends with EOF`,
			input:     "--abc",
			wantLen:   5,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `comment starts with -- ends with \n`,
			input:     "--abc\n",
			wantLen:   6,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `comment starts with /* ends with */`,
			input:     "/*abc*/",
			wantLen:   7,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `multiline comment starts with /* ends with */`,
			input:     "/*\n  This is a multiline comment\n  on multiple lines\n*/",
			wantLen:   55,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `invalid comment /*/`,
			input:     "/*/",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `incomplete comment starts with /*`,
			input:     "/* abc",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `comment ends with first */ if nested`,
			input:     "/* /* nested */ */",
			wantLen:   15,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
		{message: `comment ends with first */ if consecutive`,
			input:     "/* 1 */ /* 2 */",
			wantLen:   7,
			wantKind:  tokenize.TokenComment,
			shouldErr: false,
		},
	}

	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.Comment)
	}
}

func TestIdentifierQuoted(t *testing.T) {
	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `empty quoted identifier`,
			input:     "``",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `incomplete quoted identifier`,
			input:     "`a",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid escape sequence \`,
			input:     "`" + `\` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid escape sequence \c`,
			input:     "`" + `\c` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid octal escape sequence \678`,
			input:     "`" + `\678` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid octal escape sequence \67`,
			input:     "`" + `\67` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid hex escape sequence \x4`,
			input:     "`" + `\x4` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid hex escape sequence \X1y`,
			input:     "`" + `\X1y` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid unicode escape sequence \uabc`,
			input:     "`" + `\uabc` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid unicode escape sequence \uefgh`,
			input:     "`" + `\uefgh` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid unicode escape sequence \Uabcde`,
			input:     "`" + `\Uabcde` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains invalid unicode escape sequence \Uabcdefgh`,
			input:     "`" + `\Uabcdefgh` + "`",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted identifier contains escape sequence \a \b \f \n \r \t \v`,
			input:     "`" + `\a \b \f \n \r \t \v` + "`",
			wantLen:   22,
			wantKind:  tokenize.TokenIdentifierQuoted,
			shouldErr: false,
		},
		{message: `quoted identifier contains escape sequence \\ \? \" \'`,
			input:     "`" + `\\ \? \" \'` + "`",
			wantLen:   13,
			wantKind:  tokenize.TokenIdentifierQuoted,
			shouldErr: false,
		},
		{message: `quoted identifier contains escape sequence \770 \xFF \X00 \u00fF \U00ffFF00`,
			input:     "`" + `\770 \xFF \X00 \u00fF \U00ffFF00` + "`",
			wantLen:   34,
			wantKind:  tokenize.TokenIdentifierQuoted,
			shouldErr: false,
		},
		{message: `quoted identifier contains escaped back quote`,
			input:     string([]rune{'`', '\\', '`', '`'}),
			wantLen:   4,
			wantKind:  tokenize.TokenIdentifierQuoted,
			shouldErr: false,
		},
		{message: `quoted identifier contains any characters`,
			input:     "`_1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ~!@#$%^&*()-+={}[]|:\"'<>?,./`",
			wantLen:   93,
			wantKind:  tokenize.TokenIdentifierQuoted,
			shouldErr: false,
		},
	}

	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.IdentifierQuoted)
	}
}

func TestLiteralQuoted(t *testing.T) {
	type lqTestcase struct {
		message        string
		prefix         []string
		quote          []string
		content        string
		wantContentLen int
		wantKind       tokenize.TokenKind
		shouldErr      bool
	}
	toTestcases := func(c lqTestcase) []testcaseScan {
		ts := []testcaseScan{}
		for _, prefix := range c.prefix {
			for _, quote := range c.quote {
				input := prefix + quote + c.content + quote
				wantLen := 0
				if !c.shouldErr {
					wantLen = c.wantContentLen + +len(prefix) + 2*len(quote)
				}
				ts = append(ts, testcaseScan{
					message:   c.message + `: ` + input,
					input:     input,
					wantLen:   wantLen,
					wantKind:  c.wantKind,
					shouldErr: c.shouldErr,
				})
			}
		}
		return ts
	}
	lqTestcases := []lqTestcase{
		{message: `empty string`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `r`, `b`, `R`, `B`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        ``,
			wantContentLen: 0,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\`,
			wantContentLen: 1,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\c`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\c`,
			wantContentLen: 2,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\678`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\678`,
			wantContentLen: 4,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\67`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\67`,
			wantContentLen: 3,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\x4`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\x4`,
			wantContentLen: 3,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\X1y`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\X1y`,
			wantContentLen: 4,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\uabc`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\uabc`,
			wantContentLen: 5,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\uefgh`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\uefgh`,
			wantContentLen: 6,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\Uabcde`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\Uabcde`,
			wantContentLen: 7,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having invalid escape sequence`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`},
			content:        `\Uabcdefgh`,
			wantContentLen: 0,
			wantKind:       tokenize.TokenUnspecified,
			shouldErr:      true,
		},
		{message: `quoted literal having \`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\Uabcdefgh`,
			wantContentLen: 10,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having escape sequences`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\a \b \f \n \r \t \v`,
			wantContentLen: 20,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having escape sequences`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\\ \?`,
			wantContentLen: 5,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having escape sequences`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\770 \xFF \X00 \u00fF \U00ffFF00`,
			wantContentLen: 32,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having escape sequences`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `\770 \xAF \xaf \X09 \u09fF \u28aA \U09afAF5b`,
			wantContentLen: 44,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having escaped back quote`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        "\\`",
			wantContentLen: 2,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having valid characters`,
			quote:          []string{`'`, `"`, `'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `_1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ~!@#$%^&*()-+={}[]|:<>?,./`,
			wantContentLen: 90,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having newline`,
			quote:          []string{`'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        "two\nlines",
			wantContentLen: 9,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having newline`,
			quote:          []string{`'`, `"`},
			prefix:         []string{`r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        "two\nlines",
			wantContentLen: 9,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having a unescaped quote`,
			quote:          []string{`'''`, `"""`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `it's "double" quote`,
			wantContentLen: 19,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having a unescaped quote`,
			quote:          []string{`'`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `"double quote"`,
			wantContentLen: 14,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
		{message: `quoted literal having a unescaped quote`,
			quote:          []string{`"`},
			prefix:         []string{``, `b`, `B`, `r`, `R`, `rb`, `br`, `Rb`, `Br`, `rB`, `bR`, `RB`, `BR`},
			content:        `'single quote'`,
			wantContentLen: 14,
			wantKind:       tokenize.TokenLiteralQuoted,
			shouldErr:      false,
		},
	}

	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `incomplete quoted literal starts with '`,
			input:     `'a`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `incomplete quoted literal starts with Rb"""`,
			input:     `Rb"""a`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `quoted literal followed by quotes`,
			input:     `Rb"""a""""""`,
			wantLen:   9,
			wantKind:  tokenize.TokenLiteralQuoted,
			shouldErr: false,
		},
		{message: `quoted literal followed by quotes`,
			input:     `bR'a''''`,
			wantLen:   5,
			wantKind:  tokenize.TokenLiteralQuoted,
			shouldErr: false,
		},
		{message: `quoted literal followed by tokens`,
			input:     `Rb"""a"""abc`,
			wantLen:   9,
			wantKind:  tokenize.TokenLiteralQuoted,
			shouldErr: false,
		},
		{message: `quoted literal followed by tokens`,
			input:     `bR'a'abc`,
			wantLen:   5,
			wantKind:  tokenize.TokenLiteralQuoted,
			shouldErr: false,
		},
	}

	for _, lqTestcase := range lqTestcases {
		testcases = append(testcases, toTestcases(lqTestcase)...)
	}
	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.LiteralQuoted)
	}
}

func TestIdentifierOrKeyword(t *testing.T) {
	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `starts with not letter`,
			input:     `1`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `starts with not letter`,
			input:     " ",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `starts with underscore`,
			input:     "_12ab",
			wantLen:   5,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `starts with alphabet`,
			input:     "ab_12",
			wantLen:   5,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `identifier starts with keyword`,
			input:     "SELECT_XYZ",
			wantLen:   10,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `identifier followed by tokens`,
			input:     "_XYZ123 123",
			wantLen:   7,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `keyword followed by tokens`,
			input:     "SELECT 123",
			wantLen:   6,
			wantKind:  tokenize.TokenKeyword,
			shouldErr: false,
		},
		{message: `case-insensitive keyword`,
			input:     "sElEcT",
			wantLen:   6,
			wantKind:  tokenize.TokenKeyword,
			shouldErr: false,
		},
		{message: `type`,
			input:     "NUMERIC",
			wantLen:   7,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `type`,
			input:     "DATE",
			wantLen:   4,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `type`,
			input:     "TiMeStAmP",
			wantLen:   9,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
		{message: `type`,
			input:     "json",
			wantLen:   4,
			wantKind:  tokenize.TokenIdentifier,
			shouldErr: false,
		},
	}

	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.IdentifierOrKeyword)
	}
}

func TestNumberOrDot(t *testing.T) {
	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `letter`,
			input:     `a`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `symbol`,
			input:     `@`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `operator`,
			input:     `+`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `operator`,
			input:     `-`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.`,
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.a`,
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.1`,
			wantLen:   2,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.e`,
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.e1`,
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.e1+`,
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.02e1+`,
			wantLen:   5,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.92e-1+`,
			wantLen:   6,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.10e+912`,
			wantLen:   8,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `starts with dot`,
			input:     `.1E4`,
			wantLen:   4,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `hex`,
			input:     `0x`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `starts with 0x`,
			input:     `0xyz`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `starts with 0x`,
			input:     `0X `,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `starts with 0x`,
			input:     `1x1234`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `starts with 0x`,
			input:     `0xFf09aA`,
			wantLen:   8,
			wantKind:  tokenize.TokenLiteralInteger,
			shouldErr: false,
		},
		{message: `starts with 0x`,
			input:     `0X1fG`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `starts with 0x`,
			input:     `0X09afAF+`,
			wantLen:   8,
			wantKind:  tokenize.TokenLiteralInteger,
			shouldErr: false,
		},
		{message: `invalid integer`,
			input:     `0A`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `simple integer`,
			input:     `1`,
			wantLen:   1,
			wantKind:  tokenize.TokenLiteralInteger,
			shouldErr: false,
		},
		{message: `simple integer`,
			input:     `9876543210+`,
			wantLen:   10,
			wantKind:  tokenize.TokenLiteralInteger,
			shouldErr: false,
		},
		{message: `float`,
			input:     `123.456e-67`,
			wantLen:   11,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `0.0E+0`,
			wantLen:   6,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `9.9E9`,
			wantLen:   5,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `58.`,
			wantLen:   3,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `58.e+3`,
			wantLen:   6,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `58.E-3`,
			wantLen:   6,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `58.E+0`,
			wantLen:   6,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `float`,
			input:     `4e2`,
			wantLen:   3,
			wantKind:  tokenize.TokenLiteralFloat,
			shouldErr: false,
		},
		{message: `invalid float`,
			input:     `4e`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `1.E`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `4e+`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `4E-`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `.1E-`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `.9e+`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `1.Ee`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `4e+-`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `4E-@`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `.1E-+`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
		{message: `invalid float`,
			input:     `.9e+A`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: true,
		},
	}

	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.NumberOrDot)
	}
}

func TestSpecialChar(t *testing.T) {
	testcases := []testcaseScan{
		{message: `empty`,
			input:     ``,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `number`,
			input:     `1`,
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `underscore`,
			input:     "_",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `space`,
			input:     " ",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `alphabet`,
			input:     "a",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
		{message: `double symbols`,
			input:     ">>",
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `double symbols`,
			input:     ".>",
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		},
		{message: `dot followed by number`,
			input:     ".0",
			wantLen:   0,
			wantKind:  tokenize.TokenUnspecified,
			shouldErr: false,
		},
	}

	for _, c := range []rune("@,()[]{}<>.;:/+-~*|&^=!$?") {
		testcases = append(testcases, testcaseScan{
			message:   `special`,
			input:     string(c),
			wantLen:   1,
			wantKind:  tokenize.TokenSpecialChar,
			shouldErr: false,
		})
	}

	for _, testcase := range testcases {
		checkScan(t, testcase, tokenize.SpecialChar)
	}
}

func TestDebug(t *testing.T) {
	input := ".10e+912"
	n, c, err := tokenize.NumberOrDot(&tokenize.ScanState{Input: []rune(input)})
	t.Log(n, c, err)
}
